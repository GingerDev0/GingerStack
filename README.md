# GingerStack

A modular, self-hosted server stack installer with automatic DNS, SSL, and container management.

Built for:
- Docker + Docker Compose  
- Traefik reverse proxy  
- Cloudflare DNS automation  
- Clean, re-runnable service modules  

---

## âœ¨ Features

- ğŸ” Automatic HTTPS via Traefik + Cloudflare DNS challenge  
- ğŸ§© Modular architecture (one service = one file)  
- ğŸ” Safe to re-run individual services  
- ğŸ³ Docker-first, no host pollution  
- ğŸš€ Git-friendly (no secrets committed)  
- ğŸ›¡ï¸ Built-in brute-force protection via Traefik rate-limit middleware
- ğŸ¯ SSH Honeypot with Cowrie for early attack detection
- ğŸ›¡ï¸ WireGuard VPN for secure remote access
- ğŸ”’ Single-instance installer locking with rich diagnostics
- ğŸ§¾ Full install logging with timestamped log files
- ğŸ¤– **AI Stack with Ollama + OpenWebUI (CPU/GPU auto-optimized)**

---

## ğŸ§± Installer Safety & Reliability

GingerStack includes **production-grade installer safeguards** to ensure safe, repeatable runs.

### ğŸ”’ Single-instance locking

The installer uses a robust `flock`-based locking system (`lib/lock.sh`) to prevent multiple installs from running at the same time.

The lockfile records:
- PID and parent PID
- User and hostname
- Start timestamp
- Script path and working directory
- Bash version
- Live progress updates

If another installer is already running, GingerStack will:
- Refuse to start
- Show who is holding the lock
- Detect and warn about stale locks

This prevents race conditions, partial installs, and corrupted state.

### ğŸ§¾ Full install logging

Every installer run generates a full log file:

```
logs/install-YYYYMMDD-HHMMSS.log
```

- All stdout and stderr are captured
- Output is still streamed to the terminal
- Logs survive crashes and reboots
- The active logfile path is recorded in the lockfile

### ğŸ“ Automatic directory bootstrap

On startup, the installer ensures all required directories exist and are writable:

- `lib/`
- `logs/`
- runtime directories created by services

Missing directories are automatically created and explicitly set to:

```
chmod 0777
```

---

## ğŸ“¦ Included Services

You can enable any of these during install:

- **LAMP Stack** â€” Apache + PHP + MySQL  
- **Portainer** â€” Docker management UI  
- **Jellyfin** â€” Media streaming server  
- **qBittorrent** â€” Seedbox / download manager  
- **Immich** â€” Photo & video backup platform  
- **Mail Stack** â€” poste.io + Roundcube webmail
- **Cowrie Honeypot** â€” SSH attack detection and logging
- **WireGuard VPN** â€” Secure remote access to internal services
- **AI Stack** â€” Ollama + OpenWebUI (local LLMs)

---

## ğŸ§  AI Stack (Ollama + OpenWebUI)

GingerStack includes an **optional, fully integrated AI stack**:

- **Ollama** â€” Local LLM runtime (internal-only, never exposed)
- **OpenWebUI** â€” Secure web UI exposed via Traefik
- **Automatic CPU/GPU detection**
- **Automatic model pulling**
- **CPU tuning (all cores, optimized threading)**
- **Quantized models for fast CPU inference**
- **HTTPS + rate-limited access via Traefik**
- **Cloudflare DNS + TLS**

Default behavior:
- CPU systems pull optimized quantized models (e.g. `llama3.1:8b-instruct-q4_K_M`)
- GPU systems pull full-precision models automatically
- Models are immediately available in OpenWebUI after install

Access:
```
https://ai.your-domain.tld
```

Data directories:
```
/root/apps/ollama
/root/apps/openwebui
```

---

## âš¡ Quick Start

```bash
git clone https://github.com/GingerDev0/GingerStack.git
cd GingerStack
chmod +x install.sh
./install.sh
```

---

## ğŸ“ Project Structure

```
.
â”œâ”€ install.sh
â”œâ”€ lib/
â”œâ”€ logs/
â”œâ”€ core/
â””â”€ services/
   â”œâ”€ lamp.sh
   â”œâ”€ portainer.sh
   â”œâ”€ jellyfin.sh
   â”œâ”€ seedbox.sh
   â”œâ”€ immich.sh
   â”œâ”€ mail.sh
   â”œâ”€ honeypot.sh
   â”œâ”€ wireguard.sh
   â””â”€ ollama.sh
```

---

## ğŸ” Security Notes

- No secrets are stored in the repo  
- Cloudflare token is requested at runtime  
- TLS certificates are stored locally and ignored by git  
- All login endpoints are protected by Traefik rate-limiting middleware  
- AI backend (Ollama) is **never publicly exposed**

---

## ğŸ“œ License

MIT â€” use it, fork it, ship it.

---

Built with â˜• and Docker by **GingerDev0**
